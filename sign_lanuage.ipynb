{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "byDDf6_n3O_T"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the dataset path\n",
    "data_dir = 'Data2'\n",
    "\n",
    "# Parameters\n",
    "img_height, img_width = 128, 128  # Resize images to 128x128\n",
    "batch_size = 32\n",
    "\n",
    "# Data Augmentation and Preprocessing\n",
    "data_gen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,   # Normalize pixel values\n",
    "    validation_split=0.2,  # 20% data for validation\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L1uTv9K54n7Y",
    "outputId": "aa9955ef-b723-4b8f-fe08-d4944930238b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2029 images belonging to 9 classes.\n",
      "Found 504 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load Training and Validation Data\n",
    "train_data = data_gen.flow_from_directory(\n",
    "    directory=data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_data = data_gen.flow_from_directory(\n",
    "    directory=data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91cFPep74uOE",
    "outputId": "82d36623-4c8d-4722-c6ef-9acd36b795d0"
   },
   "outputs": [],
   "source": [
    "classes = 9\n",
    "\n",
    "# Build the Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(classes, activation='softmax')  # 9 output classes\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "vlq9WTlK4z4t"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aS5iTEtW45fT",
    "outputId": "263654ae-c7f1-4e17-d09b-9a50f7ed66a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "64/64 [==============================] - 33s 501ms/step - loss: 1.8897 - accuracy: 0.3139 - val_loss: 0.9995 - val_accuracy: 0.7480\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 30s 467ms/step - loss: 0.8880 - accuracy: 0.7048 - val_loss: 0.3504 - val_accuracy: 0.8829\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 36s 555ms/step - loss: 0.5867 - accuracy: 0.7969 - val_loss: 0.2382 - val_accuracy: 0.9365\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 35s 544ms/step - loss: 0.4855 - accuracy: 0.8305 - val_loss: 0.2211 - val_accuracy: 0.9306\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 30s 470ms/step - loss: 0.3327 - accuracy: 0.8827 - val_loss: 0.1599 - val_accuracy: 0.9464\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 30s 473ms/step - loss: 0.3195 - accuracy: 0.8886 - val_loss: 0.1176 - val_accuracy: 0.9583\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 31s 478ms/step - loss: 0.2746 - accuracy: 0.9083 - val_loss: 0.1219 - val_accuracy: 0.9663\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 30s 468ms/step - loss: 0.2961 - accuracy: 0.8985 - val_loss: 0.0848 - val_accuracy: 0.9623\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 31s 482ms/step - loss: 0.2010 - accuracy: 0.9280 - val_loss: 0.0766 - val_accuracy: 0.9722\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 32s 502ms/step - loss: 0.2050 - accuracy: 0.9305 - val_loss: 0.1238 - val_accuracy: 0.9623\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bB1nSFCs47iH",
    "outputId": "d146efc2-9e11-4f24-de22-202294640304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 3s 201ms/step - loss: 0.1002 - accuracy: 0.9683\n",
      "Validation Accuracy: 96.83%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the Model\n",
    "model.save('sign_language_model_2.h5')\n",
    "\n",
    "# Evaluate the Model\n",
    "test_loss, test_accuracy = model.evaluate(val_data)\n",
    "print(f\"Validation Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('sign_language_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def predict_class(image_path):\n",
    "    img = image.load_img(image_path, target_size=(img_height, img_width))\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    predictions = model.predict(img_array)\n",
    "    class_idx = np.argmax(predictions)\n",
    "    class_label = list(train_data.class_indices.keys())[class_idx]\n",
    "    return class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zTIkIMtc9PY4",
    "outputId": "19afb999-c018-44ee-f89f-0d51ea99639e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 118ms/step\n",
      "Predicted Class: Down\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test Example\n",
    "example_image = 'Data2\\Down\\Image_1738594012.641176.jpg'\n",
    "result = predict_class(example_image)\n",
    "print(f\"Predicted Class: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZaDH207r9qU4",
    "outputId": "66fe331d-d075-47ae-fcdc-106457669bae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "Predicted Class: Wait\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test Example\n",
    "example_image = 'Data2\\Wait\\Image_1738593619.740003.jpg'\n",
    "result = predict_class(example_image)\n",
    "print(f\"Predicted Class: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "NEvc5B0gHGRI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predicted Class: Sorry\n"
     ]
    }
   ],
   "source": [
    "# Test Example\n",
    "example_image = 'Data2\\Sorry\\Image_1738593681.600836.jpg'\n",
    "result = predict_class(example_image)\n",
    "print(f\"Predicted Class: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
